<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Scrapy | Utopia</title>
    <meta name="generator" content="VuePress 1.5.2">
    <link rel="icon" href="/myblog/assets/favicon/ico.png">
    <meta name="description" content="Mozart, Beethoven, and Chopin never died. They simply became music.">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <link rel="preload" href="/myblog/assets/css/0.styles.5091ea88.css" as="style"><link rel="preload" href="/myblog/assets/js/app.3c6bd7bd.js" as="script"><link rel="preload" href="/myblog/assets/js/3.3e419549.js" as="script"><link rel="preload" href="/myblog/assets/js/1.1d95c9eb.js" as="script"><link rel="preload" href="/myblog/assets/js/13.95335a9c.js" as="script"><link rel="prefetch" href="/myblog/assets/js/10.1841e60c.js"><link rel="prefetch" href="/myblog/assets/js/11.a612e776.js"><link rel="prefetch" href="/myblog/assets/js/12.15f7d96e.js"><link rel="prefetch" href="/myblog/assets/js/14.149ef811.js"><link rel="prefetch" href="/myblog/assets/js/15.8a892d8a.js"><link rel="prefetch" href="/myblog/assets/js/16.622f8d0f.js"><link rel="prefetch" href="/myblog/assets/js/17.d77b8951.js"><link rel="prefetch" href="/myblog/assets/js/18.2a681e6a.js"><link rel="prefetch" href="/myblog/assets/js/19.abb3a3fe.js"><link rel="prefetch" href="/myblog/assets/js/20.1f8a9189.js"><link rel="prefetch" href="/myblog/assets/js/4.06e9f2ef.js"><link rel="prefetch" href="/myblog/assets/js/5.dcea523e.js"><link rel="prefetch" href="/myblog/assets/js/6.fc6d98de.js"><link rel="prefetch" href="/myblog/assets/js/7.83356cc2.js"><link rel="prefetch" href="/myblog/assets/js/8.1210efef.js"><link rel="prefetch" href="/myblog/assets/js/9.079e9096.js">
    <link rel="stylesheet" href="/myblog/assets/css/0.styles.5091ea88.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Utopia</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>Mozart, Beethoven, and Chopin never died. They simply became music.</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>zain</span>
            
          <!---->
          2021
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/myblog/" class="home-link router-link-active"><img src="/myblog/assets/favicon/ico.png" alt="Utopia" class="logo"> <span class="site-name">Utopia</span></a> <div class="links"><!----> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/myblog/" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><a href="https://github.com/zainhubb" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="/myblog/assets/favicon/avatar.JPG" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    zain
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>10</h3> <h6 data-v-828910c6>文章</h6></div> <div data-v-828910c6><h3 data-v-828910c6>3</h3> <h6 data-v-828910c6>标签</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/myblog/" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><a href="https://github.com/zainhubb" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Scrapy</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>zain</span>
            
          <!---->
          2021
        </a></span></div></div> <div data-v-1156296a><main class="page"><section><div class="page-title"><h1 class="title">Scrapy</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>zain</span></i> <!----> <!----> <!----></div></div> <div class="theme-reco-content content__default"><h2 id="_1-scrapy介绍"><a href="#_1-scrapy介绍" class="header-anchor">#</a> 1.scrapy介绍</h2> <p><img src="/myblog/assets/img/1.e2954a38.png" alt=""></p> <h2 id="_2-安装scrapy框架"><a href="#_2-安装scrapy框架" class="header-anchor">#</a> 2.安装scrapy框架:</h2> <p>进入虚拟环境后,通过命令</p> <div class="language-shell extra-class"><pre class="language-shell"><code>pip <span class="token function">install</span> scrapy
</code></pre></div><p>来安装scrapy框架(<strong>如果在在windows下,还需要安装</strong><code>pypiwin32</code>)</p> <h2 id="_3-创建项目和爬虫"><a href="#_3-创建项目和爬虫" class="header-anchor">#</a> 3.创建项目和爬虫:</h2> <p>1.通过以下命令来创建scrapy项目</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy startproject <span class="token operator">&lt;</span>项目名称<span class="token operator">&gt;</span>
</code></pre></div><p>2.进入scrapy项目路径后,通过以下命令来创建scrapy爬虫</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy genspider <span class="token operator">&lt;</span>爬虫名称<span class="token operator">&gt;</span> <span class="token operator">&lt;</span><span class="token string">&quot;爬虫的域名&quot;</span><span class="token operator">&gt;</span>
</code></pre></div><p>创建带模板的scrapy爬虫</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy genspider -t <span class="token operator">&lt;</span>模板名称<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>爬虫名称<span class="token operator">&gt;</span> <span class="token operator">&lt;</span><span class="token string">&quot;爬虫的域名&quot;</span><span class="token operator">&gt;</span>
</code></pre></div><p><strong>(爬虫的名称不能和项目名称一样,且爬虫名称唯一</strong>)</p> <h2 id="_4-启动爬虫"><a href="#_4-启动爬虫" class="header-anchor">#</a> 4.启动爬虫</h2> <p>通过以下命令来启动爬虫</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy crawl <span class="token operator">&lt;</span>爬虫名称<span class="token operator">&gt;</span>
</code></pre></div><p>可以建立<code>start.py</code>文件,来通过启动该文件快速启动爬虫</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline
cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">&quot;scrapy&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;crawl&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;&lt;爬虫名称&gt;&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="_5-项目目录结构"><a href="#_5-项目目录结构" class="header-anchor">#</a> 5.项目目录结构</h2> <ol><li><code>items.py</code>:用来存放爬虫爬下来的数据模型</li> <li><code>middlewares.py</code>:用来存放各种中间件的文件.</li> <li><code>pipelines.py</code>:用来将items的模型存储到本地磁盘中.</li> <li><code>settings.py</code>:该爬虫的一些配置信息(比如:请求头,多久发送一次请求,ip代理池等)</li> <li><code>scrapy.cfg</code>:项目的配置信息</li> <li><code>spiders</code>文件夹:爬虫存放路径</li></ol> <h2 id="糗事百科爬虫笔记"><a href="#糗事百科爬虫笔记" class="header-anchor">#</a> 糗事百科爬虫笔记</h2> <ol><li><p><strong>response是一个<code>scrapy.http.response.html.HtmlResponse</code>对象.可以用<code>xpath</code>和<code>css</code>语法来提取数据.</strong></p></li> <li><p><strong>提取出来的数据是一个<code>Selector</code>或者一个<code>SelectorList</code>对象,如果想要过去其中的字符串应该执行<code>get()</code>方法或者<code>getall()</code>方法.</strong></p></li> <li><p><strong><code>getall()</code> 方法:获取的是<code>Selector</code>中所有文本.返回的是一个列表.</strong></p></li> <li><p><strong><code>get()</code>方法:获取的是<code>Selector</code>中的第一个文本</strong></p></li> <li><p><strong>如果数据解析回来,要传给pipeline处理,那么可以使用<code>yield</code>来返回.如果不用<code>yield</code>也可以每次将item存入一个列表,最后循环结束后将列表返回</strong></p></li> <li><p><strong>item建议在items.py中设置好模型,不要使用字典</strong></p></li> <li><p><strong>pipeline是专门用来保存数据的,其中有三个方法</strong></p> <ul><li><p><code>open_spider(self,spider)</code>:当爬虫被执行时,调用该方法.</p></li> <li><p><code>process_item(self,item,spider)</code>:当爬虫中有item传过来的时候被调用</p></li> <li><p><code>close_spider(self,spider)</code>:当爬虫被关闭时,调用该方法.</p></li></ul></li> <li><p><strong>要激活pipeline,应该先在<code>settings.py</code>中设置<code>ITEM_PIPELINES</code>.</strong></p> <div class="language- extra-class"><pre class="language-text"><code>ITEM_PIPELINES = {
   'qsbk.pipelines.QsbkPipeline': 300,
}
</code></pre></div></li></ol> <h2 id="jsonitemexporter和jsonlinesitemexport"><a href="#jsonitemexporter和jsonlinesitemexport" class="header-anchor">#</a> JsonItemExporter和JsonLinesItemExport:</h2> <p>保存Json数据的时候可以使用这两个类,让操作更简单.</p> <ol><li><p><code>JsonItemExporter</code>:这每次把数据添加到内存中,最后统一讲数据写入到磁盘中.好处是<strong>存储的是一个满足json规则的文件</strong>,坏处是<strong>比较消耗内存</strong>.示例代码如下:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.json&quot;</span><span class="token punctuation">,</span><span class="token string">'wb'</span><span class="token punctuation">)</span>
        <span class="token comment"># fp=filepoint 文件指针,代表操作的那个文件</span>
        <span class="token comment"># 启动爬虫时,打开一个&quot;duanzi.json&quot;的json文件,方便后续写入操作</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span>ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>start_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;爬虫开始了&quot;</span><span class="token punctuation">)</span>
    
    
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
    
    
    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>finish_exporting<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;爬虫结束了&quot;</span><span class="token punctuation">)</span>
</code></pre></div></li> <li><p><code>JsonLinesItemExport</code>:这个是每次调用<code>export_item</code>的时候就把item写入到磁盘中,好处是<strong>每次处理数据的时候就直接存储到了磁盘中,这样对内对消耗较少,数据也比较安全</strong>,坏处是<strong>存储的不是一个满足json规则的文件</strong>.示例代码如下:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">QsbkPipeline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;duanzi.json&quot;</span><span class="token punctuation">,</span><span class="token string">'wb'</span><span class="token punctuation">)</span>
        <span class="token comment"># fp=filepoint 文件指针,代表操作的那个文件</span>
        <span class="token comment"># 启动爬虫时,打开一个&quot;duanzi.json&quot;的json文件,方便后续写入操作</span>
        self<span class="token punctuation">.</span>exporter <span class="token operator">=</span> JsonLinesItemExporter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span>ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;爬虫开始了&quot;</span><span class="token punctuation">)</span>
    
    
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>exporter<span class="token punctuation">.</span>export_item<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
    
    
    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;爬虫结束了&quot;</span><span class="token punctuation">)</span>
</code></pre></div></li></ol> <h2 id="scrapy下载图片"><a href="#scrapy下载图片" class="header-anchor">#</a> scrapy下载图片</h2> <ol><li><p>在<code>items.py</code>设置好数据模型,<code>image_urls</code>和<code>images</code></p> <p>(***注意:***<code>image_urls</code><em><strong>必须是一个</strong></em><code>list</code>)</p> <p>(***注意:***<code>image_urls</code><em><strong>必须是一个</strong></em><code>list</code>)</p> <p>(***注意:***<code>image_urls</code><em><strong>必须是一个</strong></em><code>list</code>)</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">ImagesItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>

    image_urls <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    images <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">pass</span>
</code></pre></div></li> <li><p>在<code>settings.py</code>中设置好<code>ITEM_PIPELINES</code></p> <div class="language-py extra-class"><pre class="language-py"><code>ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token string">'scrapy.pipelines.images.ImagesPipeline'</span><span class="token punctuation">:</span><span class="token number">1</span>
<span class="token punctuation">}</span>
</code></pre></div></li> <li><p>在<code>settings.py</code>中设置好<code>IMAGES_STORE</code></p> <div class="language- extra-class"><pre class="language-text"><code>import os
IMAGES_STORE = os.path.join(os.path.dirname(os.path.dirname(__file__)),'images')
# 这里使用了os模块,设置图片存放路径为&quot;../images&quot;
</code></pre></div></li></ol></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">最后更新: </span> <span class="time">2020年8月17日晚上10点39分</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-70334359><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#_1-scrapy介绍" class="sidebar-link reco-side-_1-scrapy介绍" data-v-70334359>1.scrapy介绍</a></li><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#_2-安装scrapy框架" class="sidebar-link reco-side-_2-安装scrapy框架" data-v-70334359>2.安装scrapy框架:</a></li><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#_3-创建项目和爬虫" class="sidebar-link reco-side-_3-创建项目和爬虫" data-v-70334359>3.创建项目和爬虫:</a></li><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#_4-启动爬虫" class="sidebar-link reco-side-_4-启动爬虫" data-v-70334359>4.启动爬虫</a></li><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#_5-项目目录结构" class="sidebar-link reco-side-_5-项目目录结构" data-v-70334359>5.项目目录结构</a></li><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#糗事百科爬虫笔记" class="sidebar-link reco-side-糗事百科爬虫笔记" data-v-70334359>糗事百科爬虫笔记</a></li><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#jsonitemexporter和jsonlinesitemexport" class="sidebar-link reco-side-jsonitemexporter和jsonlinesitemexport" data-v-70334359>JsonItemExporter和JsonLinesItemExport:</a></li><li class="level-2" data-v-70334359><a href="/myblog/notes/scrapy/#scrapy下载图片" class="sidebar-link reco-side-scrapy下载图片" data-v-70334359>scrapy下载图片</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><!----><!----><div class="kanbanniang" data-v-5775ee02><div class="banniang-container" style="display:;" data-v-5775ee02><div class="messageBox" style="right:68px;bottom:190px;display:none;" data-v-5775ee02>
      欢迎来到
    </div> <div class="operation" style="right:90px;bottom:40px;display:none;" data-v-5775ee02><i class="kbnfont kbn-ban-home ban-home" data-v-5775ee02></i> <i class="kbnfont kbn-ban-message message" data-v-5775ee02></i> <i class="kbnfont kbn-ban-close close" data-v-5775ee02></i> <a target="_blank" href="https://vuepress-theme-reco.recoluan.com/views/plugins/kanbanniang.html" data-v-5775ee02><i class="kbnfont kbn-ban-info info" data-v-5775ee02></i></a> <i class="kbnfont kbn-ban-theme skin" style="display:;" data-v-5775ee02></i></div> <canvas id="banniang" width="150" height="220" class="live2d" style="right:90px;bottom:-20px;opacity:0.9;" data-v-5775ee02></canvas></div> <div class="showBanNiang" style="display:none;" data-v-5775ee02>
    看板娘
  </div></div></div></div>
    <script src="/myblog/assets/js/app.3c6bd7bd.js" defer></script><script src="/myblog/assets/js/3.3e419549.js" defer></script><script src="/myblog/assets/js/1.1d95c9eb.js" defer></script><script src="/myblog/assets/js/13.95335a9c.js" defer></script>
  </body>
</html>
